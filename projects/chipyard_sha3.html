<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>Independent Chipyard project analyzing <strong>when SHA-3 accelerator speedups survive real memory hierarchies</strong> instead of collapsing at scale. I integrated a SHA-3 RoCC with Rocket/BOOM SoCs, swept message sizes from <strong>136 B to 557 KB</strong> under Verilator + DRAMSim, and showed that <strong>single-bank inclusive L2</strong>, not the accelerator itself, quietly capped large-input speedup near <strong>120×</strong>. A redesigned <strong>multi-bank inclusive L2</strong> recovered ≈<strong>34%</strong> throughput at large inputs and pulled speedup back toward the <strong>~170× plateau</strong>.</p> <hr> <h2 id="key-questions">Key questions</h2> <ul> <li>How does SHA-3 accelerator speedup change as messages grow from cache-friendly to L2-stressing sizes?</li> <li>When speedup collapses, is the bottleneck <strong>compute</strong>, <strong>L1/TLB</strong>, or <strong>L2 banking / memory path</strong>?</li> <li>Can we recover large-input speedup <strong>purely by changing the L2 structure</strong>, keeping the SHA-3 core fixed?</li> </ul> <hr> <h2 id="approach">Approach</h2> <ul> <li> <strong>RoCC integration in Chipyard</strong> <ul> <li>Integrated a <strong>SHA-3 Rocket Custom Coprocessor (RoCC)</strong> into Rocket and BOOM SoCs.</li> <li>Fixed BOOM RoCC/FPU tie-offs so non-FPU accelerators (SHA3) integrate cleanly into the OOO pipeline.</li> </ul> </li> <li> <strong>Memory-hierarchy experiment matrix</strong> <ul> <li>Single-bank vs <strong>multi-bank inclusive L2</strong> (1 / 2 / 4 / 8 banks).</li> <li>Rocket-only vs Rocket+BOOM SoCs, SHA3 vs SW-only baselines.</li> <li>Optional sweeps for L1 size, TLB ways, and L2 concurrency to isolate the dominant bottleneck.</li> </ul> </li> <li> <strong>Automated benchmark pipeline</strong> <ul> <li>Verilator + DRAMSim2 with large timeouts to support up to <strong>557 KB</strong> messages.</li> <li>Scripts that: <ul> <li>Run <strong>HW (sha3-rocc)</strong> and <strong>SW (sha3-sw)</strong> binaries per size.</li> <li>Parse UART logs for cycle counts.</li> <li>Emit CSVs and an aggregated <code class="language-plaintext highlighter-rouge">combined_sha3_speed.csv</code> with <code class="language-plaintext highlighter-rouge">size, hw_cycles, sw_cycles, speedup</code>.</li> </ul> </li> </ul> </li> </ul> <hr> <h2 id="selected-results">Selected results</h2> <p><img src="/assets/img/sha3_speedup_vs_size_with_arrow_colored.png" alt="SHA3 speedup vs message size with multi-bank L2 improvement"></p> <ul> <li> <strong>Stable mid-size plateau</strong> <ul> <li>For <strong>≈2–70 KB</strong> messages, speedup stays around <strong>168–176×</strong>.</li> <li>SHA-3 RoCC is well-fed; the memory path is not yet the limiter.</li> </ul> </li> <li> <strong>Large inputs expose L2 banking</strong> <ul> <li>At <strong>139–278 KB</strong>, speedup decays from ~160× to ~145× as the working set stresses L2 capacity/associativity.</li> <li>At <strong>557,056 B</strong>, speedup collapses to <strong>120.27×</strong> even though the SHA-3 core is unchanged.</li> <li>Cycle-accurate traces show <strong>single-bank inclusive L2</strong> serializing miss handling, refills, and evictions.</li> </ul> </li> <li> <strong>Multi-bank L2 recovery</strong> <ul> <li>Replaced the single-bank inclusive L2 with a <strong>multi-bank inclusive L2</strong> (more capacity + sub-banking concurrency).</li> <li>At <strong>557,056 B</strong>, speedup improves from <strong>120.27× → 160.90×</strong>, a ≈<strong>34%</strong> throughput gain, nearly matching the mid-size plateau.</li> <li>The same accelerator looks like a <strong>120×</strong> unit under a narrow L2, and like a <strong>161×</strong> unit once the memory path is fixed.</li> </ul> </li> </ul> <hr> <h2 id="takeaways">Takeaways</h2> <ul> <li>At scale, <strong>accelerator speedup is set by the memory path</strong>, not the SHA-3 core: <ul> <li>Single-bank inclusive L2 quietly erodes speedups as messages outgrow cache-friendly sizes.</li> <li>Multi-bank L2 restores the promised behavior without touching the accelerator.</li> </ul> </li> <li>This project is the first step in my broader agenda: <ul> <li>Treat <strong>memory-system design and banking</strong> as first-class levers for <strong>“accelerators that keep their promises”</strong> under realistic working sets.</li> </ul> </li> </ul> </body></html>